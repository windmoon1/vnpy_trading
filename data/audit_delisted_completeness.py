"""
è„šæœ¬ 07: é€€å¸‚æ•°æ®å…¨é‡å®¡è®¡ (Data Audit)
------------------------------------------------
ç›®æ ‡: æ ¡éªŒé€€å¸‚è‚¡ç¥¨çš„è¡Œæƒ…å®Œæ•´æ€§ï¼ˆæ˜¯å¦åˆ°é€€å¸‚å‰æœ€åä¸€åˆ»ï¼‰åŠå¤æƒå› å­è¦†ç›–ç‡ã€‚
è¾“å‡º: æ§åˆ¶å°æ‘˜è¦ + è¯¦ç»† CSV æŠ¥å‘Š ('delisted_audit_report.csv')
"""
import os
import pandas as pd
from datetime import datetime, timedelta
from pymongo import MongoClient
from tqdm import tqdm
from vnpy.trader.constant import Exchange

# --- é…ç½® ---
DB_NAME = "vnpy_stock"
# è­¦å‘Šé˜ˆå€¼ï¼šå¦‚æœ (é€€å¸‚æ—¥æœŸ - æœ€åKçº¿æ—¥æœŸ) > 60å¤©ï¼Œè§†ä¸ºç–‘ä¼¼ç¼ºå¤±ï¼ˆæˆ–é•¿æœŸåœç‰Œï¼‰
GAP_THRESHOLD_DAYS = 60

# æ•°æ®åº“è¿æ¥
client = MongoClient("localhost", 27017)
db = client[DB_NAME]
col_info = db["stock_info"]
col_bar = db["bar_daily"]
col_adj = db["adjust_factor"]


def get_last_bar_date(symbol):
    """è·å–æ•°æ®åº“ä¸­è¯¥è‚¡ç¥¨æœ€åä¸€æ¡Kçº¿çš„æ—¥æœŸ"""
    doc = col_bar.find_one(
        {"symbol": symbol},
        sort=[("datetime", -1)],  # æŒ‰æ—¶é—´å€’åºå–ç¬¬ä¸€ä¸ª
        projection={"datetime": 1}
    )
    return doc["datetime"] if doc else None


def check_adjust_factor(symbol):
    """æ£€æŸ¥æ˜¯å¦æœ‰å¤æƒå› å­"""
    # åªè¦æœ‰ä¸€æ¡å› å­è®°å½•å°±ç®—æœ‰ï¼ˆé€šå¸¸ akshare ä¼šä¸€æ¬¡æ€§æ‹‰å–æ‰€æœ‰å†å²å› å­ï¼‰
    return col_adj.find_one({"symbol": symbol}, projection={"_id": 1}) is not None


def run_audit():
    print("ğŸš€ å¯åŠ¨ [é€€å¸‚è‚¡ç¥¨æ•°æ®å®¡è®¡]...")

    # 1. è·å–æ‰€æœ‰é€€å¸‚è‚¡ç¥¨åå•
    # æ³¨æ„ï¼šæˆ‘ä»¬åªå…³å¿ƒçŠ¶æ€ä¸º DELISTED çš„
    cursor = col_info.find({"status": "DELISTED"})
    delisted_stocks = list(cursor)

    if not delisted_stocks:
        print("âš ï¸ æœªåœ¨ stock_info ä¸­æ‰¾åˆ°ä»»ä½•çŠ¶æ€ä¸º DELISTED çš„è‚¡ç¥¨ã€‚è¯·å…ˆè¿è¡Œè„šæœ¬ 04ã€‚")
        return

    print(f"ğŸ“‹ å¾…å®¡è®¡è‚¡ç¥¨æ•°é‡: {len(delisted_stocks)}")

    results = []

    # 2. éå†æ£€æŸ¥
    for stock in tqdm(delisted_stocks, unit="stock"):
        symbol = stock["symbol"]
        name = stock.get("name", "Unknown")
        delisted_str = stock.get("delisted_date", "")

        # è§£æé€€å¸‚æ—¥æœŸ
        delisted_dt = None
        if delisted_str:
            try:
                if isinstance(delisted_str, str):
                    delisted_dt = datetime.strptime(delisted_str, "%Y-%m-%d")
                elif isinstance(delisted_str, datetime):
                    delisted_dt = delisted_str
            except:
                pass

        # Check 1: æœ€åè¡Œæƒ…æ—¥æœŸ
        last_bar_dt = get_last_bar_date(symbol)

        # Check 2: å¤æƒå› å­
        has_factor = check_adjust_factor(symbol)

        # åˆ¤å®šé€»è¾‘
        status = "OK"
        gap_days = -1

        if not last_bar_dt:
            status = "MISSING_BARS"  # å®Œå…¨æ²¡è¡Œæƒ…
        elif not delisted_dt:
            status = "MISSING_META"  # å…ƒæ•°æ®é‡Œæ²¡é€€å¸‚æ—¥æœŸï¼Œæ— æ³•æ ¡éªŒ
        else:
            # è®¡ç®—å·®è·
            gap = delisted_dt - last_bar_dt
            gap_days = gap.days

            if gap_days > GAP_THRESHOLD_DAYS:
                status = "LARGE_GAP"  # ç¼ºå°¾éƒ¨æ•°æ® æˆ– åœç‰Œ
            elif gap_days < -5:
                # è¿™ç§æƒ…å†µç†è®ºä¸Šä¸è¯¥å‘ç”Ÿï¼ˆKçº¿æ—¥æœŸæ™šäºé€€å¸‚æ—¥æœŸï¼‰ï¼Œé™¤éå€Ÿå£³æˆ–æ•°æ®æºé”™è¯¯
                status = "DATA_CONFLICT"

            if status == "OK" and not has_factor:
                status = "MISSING_FACTOR"  # è¡Œæƒ…æœ‰ï¼Œä½†ç¼ºå› å­

        results.append({
            "symbol": symbol,
            "name": name,
            "status": status,
            "delisted_date": delisted_dt.strftime("%Y-%m-%d") if delisted_dt else "N/A",
            "last_bar_date": last_bar_dt.strftime("%Y-%m-%d") if last_bar_dt else "N/A",
            "gap_days": gap_days if gap_days != -1 else "",
            "has_factor": has_factor
        })

    # 3. ç”ŸæˆæŠ¥å‘Š
    df = pd.DataFrame(results)

    # ç»Ÿè®¡æ‘˜è¦
    print("\n" + "=" * 40)
    print("ğŸ“Š å®¡è®¡æ‘˜è¦ (Audit Summary)")
    print("=" * 40)
    summary = df['status'].value_counts()
    print(summary)

    # å¯¼å‡º CSV
    csv_file = "data/delisted_data_audit.csv"
    df.sort_values(by="status").to_csv(csv_file, index=False, encoding="utf-8-sig")
    print(f"\nğŸ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {os.path.abspath(csv_file)}")

    # 4. æ‰“å°ä¸€äº›å…¸å‹çš„é—®é¢˜æ¡ˆä¾‹ä¾›æŠ½æŸ¥
    if not df[df['status'] != 'OK'].empty:
        print("\nğŸ” å¼‚å¸¸æ ·æœ¬æŠ½æŸ¥ (Top 5):")
        print(df[df['status'] != 'OK'].head(5).to_string(index=False))

    # 5. ç»™å‡ºå»ºè®®
    print("\nğŸ’¡ ä¿®å¤å»ºè®®:")
    if "MISSING_BARS" in summary:
        print("   - MISSING_BARS: è¿è¡Œè„šæœ¬ 04 é‡æ–°ä¸‹è½½ (å¯èƒ½å½“æ—¶ç½‘ç»œè¶…æ—¶è·³è¿‡äº†)ã€‚")
    if "MISSING_FACTOR" in summary:
        print("   - MISSING_FACTOR: è¿è¡Œè„šæœ¬ 03 è¡¥å……ä¸‹è½½å› å­ (å¯èƒ½ AkShare æ¥å£æ³¢åŠ¨)ã€‚")
    if "LARGE_GAP" in summary:
        print("   - LARGE_GAP: æ­£å¸¸ç°è±¡ã€‚å¾ˆå¤šé€€å¸‚è‚¡åœ¨çœŸæ­£æ‘˜ç‰Œå‰ä¼šç»å†æ•°æœˆçš„åœç‰Œæ•´ç†æœŸã€‚")
        print("     åªè¦ gap_days ä¸æ˜¯ç‰¹åˆ«ç¦»è°±ï¼ˆå¦‚ > 365å¤©ï¼‰ï¼Œé€šå¸¸å¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚")


if __name__ == "__main__":
    run_audit()