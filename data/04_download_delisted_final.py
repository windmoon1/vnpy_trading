"""
è„šæœ¬ 04: é€€å¸‚è‚¡ç¥¨æ¢å¤å™¨ (v7.2 æ—¶é—´é˜€é—¨ç‰ˆ)
------------------------------------------------
ç­–ç•¥å‡çº§:
1. [æ—¶é—´é˜€é—¨]: ä»…æ”¶å½• 2005-01-01 ä¹‹åé€€å¸‚çš„è‚¡ç¥¨ã€‚
   (åœ¨æ­¤ä¹‹å‰é€€å¸‚çš„è‚¡ç¥¨å¯¹å½“å‰å›æµ‹æ— æ„ä¹‰ï¼Œç›´æ¥è¿‡æ»¤)
2. [æ•°æ®å¯¹é½]: è¡Œæƒ…ä¸‹è½½èµ·ç‚¹ç»Ÿä¸€ä¸º 2005-01-01ã€‚
3. [å•ä½ç»Ÿä¸€]: ä¸¥æ ¼æ‰§è¡Œ ä¸œè´¢æˆäº¤é‡(æ‰‹) -> æ•°æ®åº“(è‚¡) çš„è½¬æ¢ã€‚
"""
import os
import time
import pandas as pd
from datetime import datetime
from tqdm import tqdm
from pymongo import UpdateOne, MongoClient
from vnpy.trader.constant import Exchange, Interval
import akshare as ak
import random

# --- ğŸ›¡ï¸ ç›´è¿è¡¥ä¸ ---
os.environ['http_proxy'] = ''
os.environ['https_proxy'] = ''
os.environ['all_proxy'] = ''
os.environ['NO_PROXY'] = '*'

# --- æ ¸å¿ƒé…ç½® ---
# 1. å†å²è¡Œæƒ…èµ·ç‚¹ (å›æµ‹åªä»è¿™é‡Œå¼€å§‹)
START_DATE = "20050101"
# 2. é€€å¸‚è¿‡æ»¤çº¿ (åœ¨æ­¤ä¹‹å‰é€€å¸‚çš„ç›´æ¥å¿½ç•¥)
FILTER_DATE = datetime(2005, 1, 1)

# æ•°æ®åº“
CLIENT = MongoClient("localhost", 27017)
db = CLIENT["vnpy_stock"]
col_bar = db["bar_daily"]
col_info = db["stock_info"]
col_adj = db["adjust_factor"]

def parse_date(date_val):
    """é€šç”¨æ—¥æœŸè§£æå™¨ï¼Œå¤„ç†å„ç§æ€ªå¼‚æ ¼å¼"""
    if pd.isna(date_val) or str(date_val).strip() == "":
        return None
    try:
        # å¸¸è§æ ¼å¼å¤„ç†
        return pd.to_datetime(date_val).to_pydatetime()
    except:
        return None

def update_delisted_metadata():
    """
    é˜¶æ®µä¸€ï¼šåŒæ­¥åå• + æ—¶é—´è¿‡æ»¤
    """
    print(f"\n[Phase 1] åŒæ­¥äº¤æ˜“æ‰€é€€å¸‚åå• (è¿‡æ»¤é˜ˆå€¼: {FILTER_DATE.strftime('%Y-%m-%d')})...")

    updates = []
    valid_count = 0
    skipped_count = 0

    # --- 1. æ·±äº¤æ‰€ ---
    try:
        df_sz = ak.stock_info_sz_delist(symbol="ç»ˆæ­¢ä¸Šå¸‚å…¬å¸")
        if not df_sz.empty:
            for _, row in df_sz.iterrows():
                symbol = str(row['è¯åˆ¸ä»£ç '])
                if symbol.startswith("200"): continue # å¿½ç•¥Bè‚¡

                # è§£æé€€å¸‚æ—¥æœŸ
                d_date = parse_date(row['ç»ˆæ­¢ä¸Šå¸‚æ—¥æœŸ'])

                # ğŸš¨ æ ¸å¿ƒè¿‡æ»¤é€»è¾‘ ğŸš¨
                if d_date and d_date < FILTER_DATE:
                    skipped_count += 1
                    continue

                updates.append(UpdateOne(
                    {"symbol": symbol},
                    {"$set": {
                        "symbol": symbol,
                        "name": str(row['è¯åˆ¸ç®€ç§°']),
                        "exchange": Exchange.SZSE.value,
                        "status": "DELISTED",
                        "delisted_date": d_date.strftime("%Y-%m-%d") if d_date else ""
                    }},
                    upsert=True
                ))
                valid_count += 1
    except Exception as e:
        print(f"   âŒ æ·±äº¤æ‰€åå•è·å–å¤±è´¥: {e}")

    # --- 2. ä¸Šäº¤æ‰€ ---
    try:
        df_sh = ak.stock_info_sh_delist(symbol="å…¨éƒ¨")
        if not df_sh.empty:
            for _, row in df_sh.iterrows():
                symbol = str(row['å…¬å¸ä»£ç '])
                if symbol.startswith("900"): continue # å¿½ç•¥Bè‚¡

                # è§£æé€€å¸‚æ—¥æœŸ (ä¸Šäº¤æ‰€å­—æ®µå« 'æš‚åœä¸Šå¸‚æ—¥æœŸ'ï¼Œé€šå¸¸å³ä¸ºé€€å¸‚ç›¸å…³èŠ‚ç‚¹)
                d_date = parse_date(row['æš‚åœä¸Šå¸‚æ—¥æœŸ'])

                # ğŸš¨ æ ¸å¿ƒè¿‡æ»¤é€»è¾‘ ğŸš¨
                if d_date and d_date < FILTER_DATE:
                    skipped_count += 1
                    continue

                updates.append(UpdateOne(
                    {"symbol": symbol},
                    {"$set": {
                        "symbol": symbol,
                        "name": str(row['å…¬å¸ç®€ç§°']),
                        "exchange": Exchange.SSE.value,
                        "status": "DELISTED",
                        "delisted_date": d_date.strftime("%Y-%m-%d") if d_date else ""
                    }},
                    upsert=True
                ))
                valid_count += 1
    except Exception as e:
        print(f"   âŒ ä¸Šäº¤æ‰€åå•è·å–å¤±è´¥: {e}")

    # 3. å†™å…¥æ•°æ®åº“
    if updates:
        col_info.bulk_write(updates)
        print(f"   ğŸ“Š åå•å¤„ç†å®Œæ¯•:")
        print(f"      âœ… å…¥åº“/æ›´æ–°: {valid_count} åª (2005å¹´åé€€å¸‚)")
        print(f"      ğŸ—‘ï¸ è¿‡æ»¤ä¸¢å¼ƒ: {skipped_count} åª (2005å¹´å‰é€€å¸‚)")
    else:
        print("   âš ï¸ æœªè·å–åˆ°æœ‰æ•ˆæ•°æ®ã€‚")

def save_bars_eastmoney(symbol, exchange, df):
    """
    ä¿å­˜è¡Œæƒ… (ä¸œè´¢æº - å•ä½æ¢ç®—)
    """
    if df.empty: return False
    updates = []
    for _, row in df.iterrows():
        try:
            # 1. æ—¥æœŸè§£æ
            date_val = row['æ—¥æœŸ']
            dt_str = str(date_val).split()[0]
            dt = datetime.strptime(dt_str, "%Y-%m-%d")

            # ğŸš¨ æ ¸å¿ƒè¿‡æ»¤: å†æ¬¡ç¡®ä¿åªå­˜ 2005-01-01 ä¹‹åçš„æ•°æ®
            if dt < FILTER_DATE:
                continue

            # 2. å•ä½æ¢ç®— (æ‰‹ -> è‚¡)
            vol_hand = float(row['æˆäº¤é‡'])
            vol_share = vol_hand * 100
            amount = float(row['æˆäº¤é¢'])

            doc = {
                "symbol": symbol,
                "exchange": exchange.value,
                "interval": Interval.DAILY.value,
                "datetime": dt,
                "open_price": float(row['å¼€ç›˜']),
                "high_price": float(row['æœ€é«˜']),
                "low_price": float(row['æœ€ä½']),
                "close_price": float(row['æ”¶ç›˜']),
                "volume": vol_share,        # âœ… è‚¡æ•°
                "turnover": amount,
                "gateway_name": "DELISTED_EM"
            }

            filter_doc = {
                "symbol": symbol,
                "exchange": exchange.value,
                "interval": Interval.DAILY.value,
                "datetime": dt
            }
            updates.append(UpdateOne(filter_doc, {"$set": doc}, upsert=True))
        except Exception:
            continue

    if updates:
        col_bar.bulk_write(updates)
        return True
    return False

def try_save_factors(symbol, exchange):
    """è·å–å¤æƒå› å­"""
    sina_symbol = ("sh" if exchange == Exchange.SSE else "sz") + symbol
    try:
        # æ³¨æ„ï¼šå› å­æ•°æ®æœ€å¥½è¿˜æ˜¯ä»ä¸Šå¸‚é¦–æ—¥å¼€å§‹æ‹¿ï¼Œä»¥ä¿è¯è®¡ç®—å‡†ç¡®ï¼Œ
        # ä½† vn.py å›æµ‹å¼•æ“é€šå¸¸åªçœ‹å›æµ‹åŒºé—´å†…çš„å› å­ã€‚
        # è¿™é‡Œæˆ‘ä»¬è¿˜æ˜¯ä» START_DATE å¼€å§‹è¯·æ±‚ã€‚
        df = ak.stock_zh_a_daily(
            symbol=sina_symbol,
            start_date=START_DATE, # 20050101
            adjust="qfq-factor"
        )

        if not df.empty and 'qfq_factor' in df.columns:
            updates = []
            for _, row in df.iterrows():
                dt = row['date']
                if isinstance(dt, str):
                    dt = datetime.strptime(dt.split()[0], "%Y-%m-%d")

                updates.append(UpdateOne(
                    {"symbol": symbol, "date": dt},
                    {"$set": {"factor": float(row['qfq_factor']), "source": "SINA_FACTOR"}},
                    upsert=True
                ))
            if updates:
                col_adj.bulk_write(updates)
                return True
    except: pass
    return False

def download_missing_data():
    """
    é˜¶æ®µäºŒï¼šè¡¥å…¨è¡Œæƒ…
    """
    print("\n[Phase 2] æ‰«æä»»åŠ¡é˜Ÿåˆ—ï¼Œè¡¥å…¨å†å²è¡Œæƒ…...")

    # 1. æ‰¾å‡ºæ‰€æœ‰ 2005 å¹´åé€€å¸‚çš„è‚¡ç¥¨
    # æ³¨æ„ï¼šå› ä¸ºPhase 1å·²ç»è¿‡æ»¤äº†ï¼Œæ‰€ä»¥stock_infoé‡Œæ ‡è®°ä¸ºDELISTEDçš„åº”è¯¥éƒ½æ˜¯ç¬¦åˆè¦æ±‚çš„
    cursor = col_info.find({"status": "DELISTED"})
    targets = list(cursor)

    # 2. ç­›é€‰çœŸæ­£ç¼ºæ•°æ®çš„
    tasks = []
    print("   ğŸ” æ­£åœ¨æ ¸å¯¹æœ¬åœ°æ•°æ®å­˜é‡...")
    for doc in targets:
        symbol = doc['symbol']
        # åªè¦æœ‰ä¸€æ¡æ•°æ®ï¼Œå°±è®¤ä¸ºä¸‹è½½è¿‡äº† (æ–­ç‚¹ç»­ä¼ )
        if col_bar.count_documents({"symbol": symbol}, limit=1) == 0:
            tasks.append(doc)

    print(f"   ğŸ“Š ç›®æ ‡é€€å¸‚è‚¡: {len(targets)} | éœ€è¡¥å…¨: {len(tasks)}")

    if not tasks:
        print("   âœ¨ æ‰€æœ‰é€€å¸‚è‚¡ç¥¨æ•°æ®å·²å°±ç»ªï¼Œæ— éœ€ä¸‹è½½ã€‚")
        return

    # 3. æ‰§è¡Œä¸‹è½½
    pbar = tqdm(tasks, unit="stock")
    success_count = 0

    for doc in pbar:
        symbol = doc['symbol']
        name = doc.get('name', symbol)
        exchange = Exchange(doc.get('exchange', 'SSE'))

        pbar.set_description(f"è¡¥å…¨ {name}")

        try:
            # è¯·æ±‚å†å²è¡Œæƒ… (ä» 20050101 å¼€å§‹)
            df = ak.stock_zh_a_hist(
                symbol=symbol,
                period="daily",
                start_date=START_DATE,
                end_date=datetime.now().strftime("%Y%m%d"),
                adjust=""
            )

            if not df.empty:
                # å­˜å‚¨ (å‡½æ•°å†…éƒ¨ä¼šå†æ¬¡æ ¡éªŒæ—¥æœŸ >= 2005-01-01)
                if save_bars_eastmoney(symbol, exchange, df):
                    # å°è¯•å› å­
                    try_save_factors(symbol, exchange)
                    success_count += 1

        except Exception as e:
            pbar.write(f"   âŒ {name} å¤±è´¥: {e}")

        time.sleep(random.uniform(60, 120))

    print(f"\nâœ¨ è¡¥å…¨ç»“æŸ! æˆåŠŸæ¢å¤ {success_count} åªè‚¡ç¥¨æ•°æ®ã€‚")

def run():
    print(f"ğŸš€ å¯åŠ¨ [é€€å¸‚è‚¡ç¥¨æ¢å¤å™¨ v7.2] (Filter: >={FILTER_DATE.strftime('%Y-%m-%d')})...")
    update_delisted_metadata()
    download_missing_data()
    print("\nğŸ‰ ä»»åŠ¡å®Œæˆã€‚")

if __name__ == "__main__":
    run()