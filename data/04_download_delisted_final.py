"""
è„šæœ¬ 04: é€€å¸‚è‚¡ç¥¨æ¢å¤å™¨ (v7.4 æ‹’ç»å¡æ­»ç‰ˆ) åˆå§‹åŒ–è¿è¡Œä¸€æ¬¡å³å¯
------------------------------------------------
ç­–ç•¥å‡çº§:
1. [å¼ºåˆ¶è¶…æ—¶]: å¼•å…¥ socket.setdefaulttimeout(20)ï¼Œé˜²æ­¢ requests æ— é™æŒ‚èµ·ã€‚
2. [é‡è¯•å¯è§]: æ‰“å°é‡è¯•æ—¥å¿—ï¼Œä¸å†é™é»˜ç­‰å¾…ã€‚
3. [å¼‚å¸¸é€æ˜]: æ˜ç¡®åŒºåˆ†ç½‘ç»œé—®é¢˜ä¸ä»£ç é€»è¾‘é”™è¯¯ã€‚
"""
import os
import time
import random
import requests
import functools
import socket  # ğŸ‘ˆ æ–°å¢
import pandas as pd
from datetime import datetime
from tqdm import tqdm
from pymongo import UpdateOne, MongoClient
from vnpy.trader.constant import Exchange, Interval
import akshare as ak

# --- ğŸ›¡ï¸ ç›´è¿è¡¥ä¸ ---
os.environ['http_proxy'] = ''
os.environ['https_proxy'] = ''
os.environ['all_proxy'] = ''
os.environ['NO_PROXY'] = '*'

# --- âš¡ æ ¸å¿ƒé…ç½® ---
# 1. å¼ºåˆ¶å…¨å±€è¶…æ—¶ (ç§’): è§£å†³ requests é»˜è®¤æ—  timeout å¯¼è‡´çš„æ— é™å¡æ­»
socket.setdefaulttimeout(5)

START_DATE = "20050101"
FILTER_DATE = datetime(2005, 1, 1)
MAX_RETRIES = 3       # å‡å°‘é‡è¯•æ¬¡æ•°ï¼Œå¿«é€Ÿå¤±è´¥
BASE_SLEEP = 2        # åŸºç¡€ä¼‘çœ ç§’æ•°

# æ•°æ®åº“
CLIENT = MongoClient("localhost", 27017)
db = CLIENT["vnpy_stock"]
col_bar = db["bar_daily"]
col_info = db["stock_info"]
col_adj = db["adjust_factor"]


def retry_request(max_retries=MAX_RETRIES, base_sleep=BASE_SLEEP):
    """
    [å·¥ç¨‹ä¼˜åŒ–] ç½‘ç»œè¯·æ±‚é‡è¯•è£…é¥°å™¨ (å¸¦æ—¥å¿— + æŒ‡æ•°é€€é¿)
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(1, max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except (requests.exceptions.ConnectionError,
                        requests.exceptions.Timeout,
                        requests.exceptions.ReadTimeout, # ğŸ‘ˆ æ•è·è¶…æ—¶
                        socket.timeout,                  # ğŸ‘ˆ æ•è· socket è¶…æ—¶
                        requests.exceptions.ChunkedEncodingError,
                        requests.exceptions.ProxyError) as e:

                    if attempt == max_retries:
                        print(f"\nâŒ [Network] {func.__name__} æœ€ç»ˆå¤±è´¥: {str(e)[:100]}...")
                        raise e

                    sleep_time = base_sleep * (2 ** (attempt - 1))
                    # ğŸ‘‡ å…³é”®ä¿®å¤: æ‰“å°å‡ºæ¥ï¼Œä¸è¦é™é»˜é‡è¯•
                    print(f"   âš ï¸ ç½‘ç»œå¡é¡¿ï¼Œæ­£åœ¨é‡è¯• {func.__name__} ({attempt}/{max_retries})ï¼Œç­‰å¾… {sleep_time}s...")
                    time.sleep(sleep_time)
                except Exception as e:
                    # é€»è¾‘é”™è¯¯/è§£æé”™è¯¯ç›´æ¥æŠ›å‡ºï¼Œä¸åæ²¡
                    print(f"\nâŒ [Logic] {func.__name__} å‘ç”Ÿéç½‘ç»œé”™è¯¯: {e}")
                    raise e
            return None
        return wrapper
    return decorator


def parse_date(date_val):
    if pd.isna(date_val) or str(date_val).strip() == "":
        return None
    try:
        return pd.to_datetime(date_val).to_pydatetime()
    except:
        return None


# --- å°è£…å¸¦é‡è¯•çš„ AKShare æ¥å£ ---

@retry_request()
def fetch_sz_delist_list():
    print("   ğŸ“¡ è¿æ¥æ·±äº¤æ‰€æ¥å£...", end="\r")
    return ak.stock_info_sz_delist(symbol="ç»ˆæ­¢ä¸Šå¸‚å…¬å¸")

@retry_request()
def fetch_sh_delist_list():
    print("   ğŸ“¡ è¿æ¥ä¸Šäº¤æ‰€æ¥å£...", end="\r")
    return ak.stock_info_sh_delist(symbol="å…¨éƒ¨")

@retry_request()
def fetch_stock_history(symbol):
    return ak.stock_zh_a_hist(
        symbol=symbol,
        period="daily",
        start_date=START_DATE,
        end_date=datetime.now().strftime("%Y%m%d"),
        adjust=""
    )

@retry_request()
def fetch_stock_factor(sina_symbol):
    return ak.stock_zh_a_daily(
        symbol=sina_symbol,
        start_date=START_DATE,
        adjust="qfq-factor"
    )


def update_delisted_metadata():
    """é˜¶æ®µä¸€ï¼šåŒæ­¥åå•"""
    print(f"\n[Phase 1] åŒæ­¥äº¤æ˜“æ‰€é€€å¸‚åå• (Timeout set to 20s)...")

    updates = []
    valid_count = 0

    # --- 1. æ·±äº¤æ‰€ ---
    try:
        df_sz = fetch_sz_delist_list()
        if not df_sz.empty:
            for _, row in df_sz.iterrows():
                symbol = str(row['è¯åˆ¸ä»£ç '])
                if symbol.startswith("200"): continue
                d_date = parse_date(row['ç»ˆæ­¢ä¸Šå¸‚æ—¥æœŸ'])
                if d_date and d_date < FILTER_DATE: continue

                updates.append(UpdateOne(
                    {"symbol": symbol},
                    {"$set": {
                        "symbol": symbol,
                        "name": str(row['è¯åˆ¸ç®€ç§°']),
                        "exchange": Exchange.SZSE.value,
                        "status": "DELISTED",
                        "delisted_date": d_date.strftime("%Y-%m-%d") if d_date else ""
                    }},
                    upsert=True
                ))
                valid_count += 1
            print("   âœ… æ·±äº¤æ‰€åå•è·å–æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ æ·±äº¤æ‰€åå•è·å–è·³è¿‡: {e}")

    # --- 2. ä¸Šäº¤æ‰€ ---
    try:
        df_sh = fetch_sh_delist_list()
        if not df_sh.empty:
            for _, row in df_sh.iterrows():
                symbol = str(row['å…¬å¸ä»£ç '])
                if symbol.startswith("900"): continue
                d_date = parse_date(row['æš‚åœä¸Šå¸‚æ—¥æœŸ'])
                if d_date and d_date < FILTER_DATE: continue

                updates.append(UpdateOne(
                    {"symbol": symbol},
                    {"$set": {
                        "symbol": symbol,
                        "name": str(row['å…¬å¸ç®€ç§°']),
                        "exchange": Exchange.SSE.value,
                        "status": "DELISTED",
                        "delisted_date": d_date.strftime("%Y-%m-%d") if d_date else ""
                    }},
                    upsert=True
                ))
                valid_count += 1
            print("   âœ… ä¸Šäº¤æ‰€åå•è·å–æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ ä¸Šäº¤æ‰€åå•è·å–è·³è¿‡: {e}")

    # 3. å†™å…¥æ•°æ®åº“
    if updates:
        col_info.bulk_write(updates)
        print(f"   ğŸ“Š åå•åŒæ­¥å®Œæ¯•: {valid_count} åªç›®æ ‡è‚¡ç¥¨å…¥åº“ã€‚")
    else:
        print("   âš ï¸ æœªèƒ½è·å–æ–°çš„åå•æ•°æ®ã€‚")


def save_bars_eastmoney(symbol, exchange, df):
    """ä¿å­˜è¡Œæƒ…"""
    if df.empty: return False
    updates = []
    records = df.to_dict('records')

    for row in records:
        try:
            date_val = row['æ—¥æœŸ']
            dt_str = str(date_val).split()[0]
            dt = datetime.strptime(dt_str, "%Y-%m-%d")
            if dt < FILTER_DATE: continue

            vol_share = float(row['æˆäº¤é‡']) * 100
            amount = float(row['æˆäº¤é¢'])

            doc = {
                "symbol": symbol,
                "exchange": exchange.value,
                "interval": Interval.DAILY.value,
                "datetime": dt,
                "open_price": float(row['å¼€ç›˜']),
                "high_price": float(row['æœ€é«˜']),
                "low_price": float(row['æœ€ä½']),
                "close_price": float(row['æ”¶ç›˜']),
                "volume": vol_share,
                "turnover": amount,
                "gateway_name": "DELISTED_EM"
            }
            filter_doc = {"symbol": symbol, "exchange": exchange.value, "interval": Interval.DAILY.value, "datetime": dt}
            updates.append(UpdateOne(filter_doc, {"$set": doc}, upsert=True))
        except Exception:
            continue

    if updates:
        col_bar.bulk_write(updates, ordered=False)
        return True
    return False


def try_save_factors(symbol, exchange):
    """è·å–å¤æƒå› å­"""
    sina_symbol = ("sh" if exchange == Exchange.SSE else "sz") + symbol
    try:
        df = fetch_stock_factor(sina_symbol)
        if df is not None and not df.empty and 'qfq_factor' in df.columns:
            updates = []
            records = df.to_dict('records')
            for row in records:
                dt = row['date']
                if isinstance(dt, str): dt = datetime.strptime(dt.split()[0], "%Y-%m-%d")
                updates.append(UpdateOne(
                    {"symbol": symbol, "date": dt},
                    {"$set": {"factor": float(row['qfq_factor']), "source": "SINA_FACTOR"}},
                    upsert=True
                ))
            if updates:
                col_adj.bulk_write(updates, ordered=False)
    except: pass


def download_missing_data():
    """é˜¶æ®µäºŒï¼šè¡¥å…¨è¡Œæƒ…"""
    print("\n[Phase 2] æ‰«æä»»åŠ¡é˜Ÿåˆ—ï¼Œè¡¥å…¨å†å²è¡Œæƒ…...")
    cursor = col_info.find({"status": "DELISTED"})
    targets = list(cursor)

    tasks = []
    print("   ğŸ” æ ¸å¯¹æœ¬åœ°æ•°æ®...")
    for doc in targets:
        symbol = doc['symbol']
        if col_bar.count_documents({"symbol": symbol}, limit=1) == 0:
            tasks.append(doc)

    print(f"   ğŸ“Š éœ€è¡¥å…¨: {len(tasks)} / {len(targets)}")

    if not tasks: return

    # Tqdm é…ç½®: å®æ—¶æ˜¾ç¤ºå½“å‰å¤„ç†çš„è‚¡ç¥¨
    pbar = tqdm(tasks, unit="stock")
    success_count = 0

    for doc in pbar:
        symbol = doc['symbol']
        name = doc.get('name', symbol)
        exchange = Exchange(doc.get('exchange', 'SSE'))

        pbar.set_description(f"Processing {symbol}")

        try:
            df = fetch_stock_history(symbol) # å¦‚æœè¿™é‡Œè¶…æ—¶ï¼Œä¼šæŠ›å‡ºå¼‚å¸¸è¢«ä¸‹é¢æ•è·

            if df is not None and not df.empty:
                if save_bars_eastmoney(symbol, exchange, df):
                    try_save_factors(symbol, exchange)
                    success_count += 1

        except Exception as e:
            # è¿™é‡Œçš„ print ç¡®ä¿æŠ¥é”™ä¸ä¼šè¢«â€œåæ‰â€
            pbar.write(f"   âŒ {name}({symbol}) å¤±è´¥: {str(e)[:50]}")

        #time.sleep(random.uniform(3, 5))

    print(f"\nâœ¨ ä»»åŠ¡å®Œæˆ! æˆåŠŸæ¢å¤ {success_count} åªè‚¡ç¥¨ã€‚")


if __name__ == "__main__":
    print(f"ğŸš€ å¯åŠ¨ [é€€å¸‚è‚¡ç¥¨æ¢å¤å™¨ v7.4 Anti-Freeze]...")
    # update_delisted_metadata()
    download_missing_data()
    print("\nğŸ‰ All Done.")