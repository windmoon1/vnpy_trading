# data/14_compute_suspensions.py
import numpy as np
import pandas as pd
from pymongo import MongoClient, UpdateOne, ASCENDING
from datetime import datetime
from tqdm import tqdm

# ---------------- Configuration ----------------
MONGO_HOST = "localhost"
MONGO_PORT = 27017

# æ•°æ®åº“é…ç½® (æ ¹æ®ä½ çš„å®žé™…æƒ…å†µè°ƒæ•´)
# å‡è®¾ä½ çš„æ—¥åŽ†å¯èƒ½åœ¨ vnpy_stock æˆ– vnpy_masterï¼Œè¿™é‡Œæˆ‘ä¼šéƒ½è¯•ä¸€ä¸‹
DB_STOCK_NAME = "vnpy_stock"
DB_MASTER_NAME = "vnpy_master"

# é›†åˆåç§°é…ç½®
COL_CALENDAR = "trade_date_hist"  # æˆ– "trading_calendar"ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨å°è¯•
COL_INDEX = "index_daily"
COL_STOCK = "stock_daily"
COL_STATUS = "stock_status_history"


# å­—æ®µé…ç½®
# æ—¥åŽ†è¡¨é€šå¸¸åªæœ‰ä¸€ä¸ª date å­—æ®µ
# æŒ‡æ•°/è‚¡ç¥¨è¡¨é‡Œå¯èƒ½æ˜¯ date æˆ– datetime
# -----------------------------------------------

def get_db_client():
    return MongoClient(MONGO_HOST, MONGO_PORT)


def load_calendar_from_collection(client, db_name, col_name, date_field="date"):
    """å°è¯•ä»ŽæŒ‡å®šåº“è¡¨åŠ è½½æ—¥åŽ†"""
    try:
        db = client[db_name]
        if col_name not in db.list_collection_names():
            return None

        print(f"   Trying [{db_name}.{col_name}]...")
        cursor = db[col_name].find({}, {date_field: 1, "_id": 0}).sort(date_field, ASCENDING)
        dates = [x.get(date_field) for x in cursor if x.get(date_field)]

        if dates:
            return pd.to_datetime(dates).sort_values().unique()
    except Exception as e:
        print(f"   âš ï¸ Error reading {db_name}.{col_name}: {e}")
    return None


def get_master_calendar(client):
    """
    æ™ºèƒ½èŽ·å–åŸºå‡†äº¤æ˜“æ—¥åŽ†
    ä¼˜å…ˆçº§: äº¤æ˜“æ—¥åŽ†è¡¨ > ä¸Šè¯æŒ‡æ•°
    """
    print("ðŸ“… Initializing Master Calendar...")

    # 1. å°è¯•ä»Ž vnpy_stock æˆ– vnpy_master è¯»å–äº¤æ˜“æ—¥åŽ†
    # å¸¸è§çš„é›†åˆå: trade_date_hist (AKShareé»˜è®¤), trading_calendar (vnpyé»˜è®¤)
    candidates = [
        (DB_STOCK_NAME, "trade_date_hist", "trade_date"),  # AKShare tool ä¹Ÿå°±æ˜¯ 09å·è„šæœ¬é€šå¸¸å­˜ä¸º trade_date
        (DB_STOCK_NAME, "trading_calendar", "date"),
        (DB_MASTER_NAME, "trading_calendar", "date"),
    ]

    for db_name, col_name, date_field in candidates:
        dates = load_calendar_from_collection(client, db_name, col_name, date_field)
        if dates is not None and len(dates) > 0:
            print(f"âœ… Loaded Master Calendar from [{db_name}.{col_name}]. Total: {len(dates)}")
            return dates

    # 2. Fallback: ä½¿ç”¨ä¸Šè¯æŒ‡æ•°
    print("âš ï¸ No standalone calendar found. Fallback to Index (sh000001)...")
    db = client[DB_STOCK_NAME]
    cursor = db[COL_INDEX].find({"symbol": "sh000001"}, {"datetime": 1, "_id": 0}).sort("datetime", ASCENDING)
    dates = [x.get("datetime") for x in cursor]

    if dates:
        dt_index = pd.to_datetime(dates).sort_values().unique()
        print(f"âœ… Loaded Index Calendar (sh000001). Total: {len(dt_index)}")
        return dt_index

    raise RuntimeError("âŒ CRITICAL: Could not generate Master Calendar! No calendar table and no index data found.")


def compute_suspensions(client, master_calendar):
    """
    æ ¸å¿ƒè®¡ç®—é€»è¾‘
    """
    db = client[DB_STOCK_NAME]
    collection_status = db[COL_STATUS]

    print("Fetching stock list...")
    stocks = db[COL_STOCK].distinct("symbol")
    stocks.sort()

    print(f"ðŸš€ Analyzing {len(stocks)} stocks for suspension gaps...")

    ops = []

    # é¢„è®¡ç®—: å°† master_calendar è½¬ä¸º numpy array ä»¥åŠ é€Ÿæœç´¢
    # ç¡®ä¿æ˜¯ datetime64[ns] ç±»åž‹
    master_arr = master_calendar.values.astype('datetime64[D]')

    pbar = tqdm(stocks)
    for symbol in pbar:
        try:
            # 1. èŽ·å–ä¸ªè‚¡æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
            # å…¼å®¹ date å’Œ datetime å­—æ®µ
            projection = {"date": 1, "datetime": 1, "_id": 0}
            cursor = db[COL_STOCK].find({"symbol": symbol}, projection)

            stock_dates = []
            for doc in cursor:
                # ä¼˜å…ˆå– datetime (å­—ç¬¦ä¸²), å…¶æ¬¡å– date (datetime obj)
                d = doc.get("datetime") or doc.get("date")
                if d:
                    stock_dates.append(d)

            if not stock_dates:
                continue

            # è½¬ä¸º datetime64[D]
            actual_dates = pd.to_datetime(stock_dates).values.astype('datetime64[D]')
            actual_dates.sort()

            # 2. ç¡®å®šç”Ÿå‘½å‘¨æœŸ (ä¸Šå¸‚æ—¥ ~ é€€å¸‚æ—¥/æœ€æ–°æ•°æ®æ—¥)
            min_date = actual_dates[0]
            max_date = actual_dates[-1]

            # 3. æˆªå–ç†è®ºåº”æœ‰çš„äº¤æ˜“æ—¥ (Expected)
            # åœ¨ Master ä¸­æ‰¾åˆ° min_date å’Œ max_date çš„ä½ç½®
            # searchsorted: find indices where elements should be inserted to maintain order
            start_idx = np.searchsorted(master_arr, min_date)
            end_idx = np.searchsorted(master_arr, max_date, side='right')

            expected_slice = master_arr[start_idx:end_idx]

            # 4. è®¡ç®—å·®é›† (Suspensions = Expected - Actual)
            # np.setdiff1d è¿”å›žåœ¨ expected ä¸­ä½†ä¸åœ¨ actual ä¸­çš„å…ƒç´ 
            susp_dates_arr = np.setdiff1d(expected_slice, actual_dates)

            if len(susp_dates_arr) == 0:
                continue

            # 5. å°†ç¦»æ•£æ—¥æœŸåˆå¹¶ä¸ºåŒºé—´
            intervals = []

            # æŠ€å·§: å¯»æ‰¾è¿žç»­çš„ç´¢å¼•
            # é¦–å…ˆæ‰¾åˆ° susp_dates åœ¨ master_arr ä¸­çš„ç´¢å¼•ä½ç½®
            # æ¯”å¦‚ master æ˜¯ [1,2,3,4,5], susp æ˜¯ [2,3,5]
            # indices æ˜¯ [1,2,4]
            # diff æ˜¯ [1, 2] -> 2ä¸ç­‰äºŽ1ï¼Œè¯´æ˜Žæ–­å¼€äº†

            # è¿™é‡Œæˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•çš„å¾ªçŽ¯æ¥åˆå¹¶åŒºé—´ï¼Œè™½ç„¶ä¸æ˜¯æœ€å¿«ä½†é€»è¾‘æœ€æ¸…æ™°
            # å°† numpy datetime64 è½¬å›ž pandas Timestamp ä»¥ä¾¿æå– .date()
            susp_dates_pd = pd.to_datetime(susp_dates_arr)

            if len(susp_dates_pd) > 0:
                current_start = susp_dates_pd[0]
                current_end = susp_dates_pd[0]

                # èŽ·å– master ä¸­å¯¹åº”çš„ç´¢å¼•ï¼Œç”¨äºŽåˆ¤æ–­"æ˜¯å¦ç´§é‚»çš„äº¤æ˜“æ—¥"
                # isin é®ç½©
                mask = np.isin(master_arr, susp_dates_arr)
                susp_indices = np.where(mask)[0]  # master ä¸­çš„ç´¢å¼•ä½ç½®

                # åˆ†ç»„: å¦‚æžœ index æ˜¯è¿žç»­çš„ (diff==1)ï¼Œåˆ™å±žäºŽåŒä¸€æ³¢åœç‰Œ
                # ä½¿ç”¨ shift æ¯”è¾ƒ
                if len(susp_indices) > 0:
                    # group_id ä¼šåœ¨ç´¢å¼•ä¸è¿žç»­æ—¶å¢žåŠ 
                    # [1, 2, 4, 5] -> diff -> [1, 2, 1] -> diff!=1 -> [False, True, False] -> cumsum -> [0, 1, 1, 1] ...
                    # æ›´ç®€å•çš„æ–¹æ³•: x - i (å¦‚æžœè¿žç»­ï¼Œè¿™ä¸ªå·®å€¼æ˜¯å¸¸æ•°)
                    groups = susp_indices - np.arange(len(susp_indices))

                    # éåŽ†åˆ†ç»„
                    unique_groups = np.unique(groups)
                    for g in unique_groups:
                        group_indices = susp_indices[groups == g]
                        # æ˜ å°„å›žæ—¥æœŸ
                        start_dt = pd.to_datetime(master_arr[group_indices[0]])
                        end_dt = pd.to_datetime(master_arr[group_indices[-1]])

                        intervals.append({
                            "start": start_dt,
                            "end": end_dt,
                            "reason": "Missing Data (Inferred)"
                        })

            # 6. å­˜å…¥æ•°æ®åº“
            if intervals:
                ops.append(
                    UpdateOne(
                        {"symbol": symbol},
                        {"$set": {
                            "suspensions": intervals,
                            "suspension_source": "calendar_inference",
                            "updated_at": datetime.now()
                        }},
                        upsert=True
                    )
                )

        except Exception as e:
            pbar.write(f"âš ï¸ Error {symbol}: {e}")
            continue

        if len(ops) >= 1000:
            collection_status.bulk_write(ops)
            ops = []

    if ops:
        collection_status.bulk_write(ops)

    print(f"\nâœ… Done! Processed {len(stocks)} stocks.")


if __name__ == "__main__":
    client = get_db_client()
    master_cal = get_master_calendar(client)

    if master_cal is not None:
        compute_suspensions(client, master_cal)