"""
è„šæœ¬ 03 (V2.0): å¤æƒå› å­ä¸‹è½½å™¨ (å¢é‡ä¿®å¤ç‰ˆ) éœ€è¦æ¯å¤©è¿è¡Œ
===========================================
ç›®æ ‡: æ¯æ—¥å¢é‡æ›´æ–°æ‰€æœ‰è‚¡ç¥¨çš„å‰å¤æƒå› å­ï¼ˆqfq-factorï¼‰ã€‚
ç­–ç•¥:
  1. ä¼˜å…ˆä»æœ¬åœ° stock_info è¯»å–åˆ—è¡¨ã€‚
  2. æŸ¥è¯¢ adjust_factor è¡¨ä¸­çš„æœ€æ–°æ—¥æœŸã€‚
  3. ä»æœ€æ–°æ—¥æœŸå®‰å…¨å›æº¯ä¸¤å¹´ï¼ˆé¿å…é—æ¼å› å­å˜åŠ¨ï¼‰ï¼Œå¹¶å¢é‡ä¸‹è½½åˆ°ä»Šå¤©ã€‚
-------------------------------------------
"""
import time
import random
from datetime import datetime, timedelta # âœ… æ–°å¢å¯¼å…¥ timedelta
from tqdm import tqdm
from pymongo import UpdateOne, MongoClient
from vnpy.trader.constant import Exchange
import akshare as ak
import pandas as pd
import requests
import re


# --- é…ç½® ---
ADJUST = "qfq-factor" # æ ¸å¿ƒå‚æ•°ï¼šè¯·æ±‚å‰å¤æƒä¹˜æ•°å› å­
START_DATE = "19900101" # é¦–æ¬¡ä¸‹è½½çš„èµ·å§‹æ—¥æœŸ

# --- æ•°æ®åº“è¿æ¥ ---
CLIENT = MongoClient("localhost", 27017)
db = CLIENT["vnpy_stock"]
col_adj = db["adjust_factor"] # ç›®æ ‡é›†åˆ
col_info = db["stock_info"] # åŸºç¡€ä¿¡æ¯é›†åˆ

def get_symbols():
    """ä»æœ¬åœ°æ•°æ®åº“è¯»å–æ‰€æœ‰è‚¡ç¥¨ä»£ç  (ä»…é™ Aè‚¡/åŒ—äº¤æ‰€)"""
    # æŸ¥æ‰¾ category ä¸º STOCK_A æˆ– STOCK_BJ çš„è‚¡ç¥¨
    cursor = col_info.find(
        {"category": {"$in": ["STOCK_A", "STOCK_BJ", "UNKNOWN_A"]}},
        {"symbol": 1, "exchange": 1}
    )
    # è¿”å› List[Tuple(symbol, exchange_value)]
    return [(doc['symbol'], doc.get('exchange')) for doc in cursor]

def get_sina_symbol(symbol, exchange_value):
    """æ ¹æ®äº¤æ˜“æ‰€æ¨æ–­æ–°æµªæŸ¥è¯¢å‰ç¼€"""
    if exchange_value == Exchange.SSE.value: return f"sh{symbol}"
    if exchange_value == Exchange.SZSE.value: return f"sz{symbol}"
    if exchange_value == Exchange.BSE.value: return f"bj{symbol}" # åŒ—äº¤æ‰€ä¿®æ­£ä¸º bj å‰ç¼€
    return f"sz{symbol}"

def get_incremental_start_date_factor(symbol: str) -> datetime:
    """
    [NEW] æŸ¥è¯¢ adjust_factor è¡¨ä¸­æŸä¸ªè‚¡ç¥¨çš„æœ€æ–°å› å­æ—¥æœŸï¼Œ
    è¿”å›éœ€è¦å¼€å§‹ä¸‹è½½çš„æ—¥æœŸå¯¹è±¡ (æœ€æ–°æ—¥æœŸ - 2 å¹´çš„å®‰å…¨å›æº¯æœŸ)ã€‚
    """
    doc = col_adj.find_one(
        {"symbol": symbol},
        sort=[("date", -1)],
        projection={"date": 1}
    )

    if doc and 'date' in doc:
        latest_dt = doc['date'].replace(tzinfo=None)
        # å®‰å…¨å›æº¯ 2 å¹´ï¼Œé¿å…å› å­å˜åŠ¨å¯¼è‡´ç¼ºå¤± (API è¿”å›çš„æ˜¯å…¨é‡å› å­ï¼Œä½†è¿™é‡Œä¼˜åŒ–æŸ¥è¯¢èŒƒå›´)
        return latest_dt - timedelta(days=365 * 2)

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•è®°å½•ï¼Œè¿”å›å…¨å±€ START_DATE
    return datetime.strptime(START_DATE, "%Y%m%d")


def download_and_save_factor(symbol, exchange_value, pbar, start_date_factor):
    """æ ¸å¿ƒä¸‹è½½ä¸å†™å…¥é€»è¾‘ (ä½¿ç”¨å¢é‡æ—¥æœŸ)"""
    sina_symbol = get_sina_symbol(symbol, exchange_value)

    try:
        # æ ¸å¿ƒè°ƒç”¨: è·å–å› å­æ•°æ® (ä½¿ç”¨ä¼ å…¥çš„ start_date_factor)
        df = ak.stock_zh_a_daily(
            symbol=sina_symbol,
            start_date=start_date_factor, # <-- ä½¿ç”¨å¢é‡èµ·å§‹æ—¥æœŸ
            end_date=datetime.now().strftime("%Y%m%d"),
            adjust=ADJUST
        )

        if df.empty or 'qfq_factor' not in df.columns:
            pbar.write(f"âš ï¸ {symbol}: æ¥å£è¿”å›ç©ºæˆ–ç¼ºå°‘ qfq_factor å­—æ®µã€‚")
            return 0

        updates = []
        for _, row in df.iterrows():
            try:
                # ğŸš¨ æ—¥æœŸè§£æ: å…¼å®¹ datetime.date å¯¹è±¡å’Œ ISODate å­—ç¬¦ä¸²
                if isinstance(row['date'], datetime):
                    dt = row['date'].replace(tzinfo=None) # å»é™¤æ—¶åŒºä¿¡æ¯
                elif isinstance(row['date'], pd.Timestamp):
                    dt = row['date'].to_pydatetime().replace(tzinfo=None)
                else:
                    # å‡å®šä¸º YYYY-MM-DD æ ¼å¼çš„å­—ç¬¦ä¸²
                    dt_str_clean = str(row['date']).split()[0]
                    dt = datetime.strptime(dt_str_clean, "%Y-%m-%d")

                # æ„é€ æ–‡æ¡£ (Upsert ä¿è¯ä¸é‡å¤)
                updates.append(UpdateOne(
                    {"symbol": symbol, "date": dt},
                    {"$set": {"factor": float(row['qfq_factor']), "source": "SINA_FACTOR"}},
                    upsert=True
                ))
            except Exception:
                continue

        if updates:
            result = col_adj.bulk_write(updates)
            pbar.write(f"âœ… {symbol}: æˆåŠŸå†™å…¥/æ›´æ–° {result.upserted_count + result.modified_count} æ¡å› å­è®°å½•ã€‚")
            return len(updates)
        return 0

    except requests.exceptions.ConnectionError:
        pbar.write(f"âŒ {symbol}: ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œç­‰å¾…é‡è¯•ã€‚")
        return 0
    except Exception as e:
        # æ•è·å…¶ä»–è‡´å‘½é”™è¯¯ï¼Œå¦‚ Key error æˆ– AkShare å†…éƒ¨é”™è¯¯
        pbar.write(f"âŒ {symbol}: è‡´å‘½é”™è¯¯ ({e.__class__.__name__})ï¼Œè·³è¿‡ã€‚")
        return 0


def run_factor_download():
    print("ğŸš€ å¯åŠ¨ [å¤æƒå› å­] å¢é‡ä¸‹è½½ä»»åŠ¡ (V2.0)...")
    tasks = get_symbols()

    # æ£€æŸ¥å¢é‡ä»»åŠ¡æ˜¯å¦å·²ç»å®Œæˆåˆ°ä»Šå¤©
    # ä¼˜åŒ–ï¼šä¸å†ä½¿ç”¨ done_factor åˆ—è¡¨ï¼Œè€Œæ˜¯é€šè¿‡æ—¥æœŸåˆ¤æ–­

    print(f"âœ… å…±æœ‰ {len(tasks)} åªè‚¡ç¥¨ï¼Œå‡†å¤‡è¿›è¡Œå¢é‡æ›´æ–°ã€‚")

    pbar = tqdm(tasks, unit="stock")

    for symbol, exchange_value in pbar:
        # 1. ç¡®å®šå¢é‡èµ·å§‹æ—¥æœŸ (å®‰å…¨å›æº¯ä¸¤å¹´ï¼Œæˆ–è€…ä»å¤´å¼€å§‹)
        incremental_dt = get_incremental_start_date_factor(symbol)

        # å¦‚æœæœ€æ–°æ—¥æœŸå·²ç»åˆ°ä»Šå¤©/æ˜¨å¤©ï¼Œè·³è¿‡
        yesterday_dt_str = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")
        if incremental_dt.strftime("%Y%m%d") > yesterday_dt_str:
            continue

        pbar.set_description(f"Processing {symbol} (Start: {incremental_dt.strftime('%Y%m%d')})")

        # 2. è°ƒç”¨æ ¸å¿ƒä¸‹è½½é€»è¾‘ (å«é‡è¯•)
        for attempt in range(3):
            count = download_and_save_factor(symbol, exchange_value, pbar, incremental_dt.strftime("%Y%m%d"))
            if count > 0:
                break
            elif attempt < 2:
                time.sleep(1)

        time.sleep(random.uniform(0.1, 0.3))

    print("\nâœ¨ å¤æƒå› å­ä¸‹è½½å®Œæˆï¼")

if __name__ == "__main__":
    run_factor_download()