# data/14_download_suspension_by_date.py

import akshare as ak
import pandas as pd
from pymongo import MongoClient, UpdateOne, ASCENDING
from datetime import datetime, timedelta
from tqdm import tqdm
import time

# ---------------- Configuration ----------------
MONGO_HOST = "localhost"
MONGO_PORT = 27017
DB_NAME = "vnpy_stock"

# å­˜æ¯å¤©åŸå§‹æ•°æ®çš„é›†åˆ (ä¸´æ—¶/ç¼“å†²)
COL_DAILY_RAW = "suspension_daily_raw"
# æœ€ç»ˆå­˜å…¥çš„ç›®æ ‡é›†åˆ (ä¸ ST çŠ¶æ€å…±å­˜)
COL_TARGET = "stock_status_history"

# èµ·å§‹æ—¥æœŸ (ä¸œè´¢æ•°æ®å¤§çº¦ä» 2005 å¹´å¼€å§‹æ¯”è¾ƒå…¨)
START_DATE = "20050101"


# -----------------------------------------------

def get_db():
    client = MongoClient(MONGO_HOST, MONGO_PORT)
    return client[DB_NAME]


def get_trading_calendar(db):
    """è·å–äº¤æ˜“æ—¥å†åˆ—è¡¨"""
    print("ğŸ“… Loading Trading Calendar...")
    # ä¼˜å…ˆç”¨äº¤æ˜“æ—¥å†è¡¨ï¼Œæ²¡æœ‰åˆ™ç”¨æŒ‡æ•°å…œåº•
    col = db["trade_date_hist"] if "trade_date_hist" in db.list_collection_names() else db["index_daily"]

    query = {}
    field = "trade_date" if col.name == "trade_date_hist" else "date"
    if col.name == "index_daily":
        query = {"symbol": "sh000001"}
        # å…¼å®¹ä½ çš„ datetime å­—æ®µ
        if db[col.name].find_one(query, {"datetime": 1}):
            field = "datetime"

    cursor = col.find(query, {field: 1, "_id": 0}).sort(field, ASCENDING)
    dates = []
    for doc in cursor:
        d_val = doc.get(field)
        if d_val:
            dates.append(pd.to_datetime(d_val))

    # è¿‡æ»¤ 2005 å¹´ä»¥åçš„æ—¥æœŸ
    dates = sorted(list(set(dates)))
    dates = [d for d in dates if d >= pd.Timestamp(START_DATE)]

    print(f"âœ… Calendar Ready: {len(dates)} days from {dates[0].date()} to {dates[-1].date()}")
    return dates


def download_daily_suspensions(db, dates):
    """
    Step 1: æŒ‰æ—¥æœŸä¸‹è½½å¹¶å­˜å…¥ suspension_daily_raw
    """
    collection = db[COL_DAILY_RAW]
    # å»ºç´¢å¼•æ–¹ä¾¿å»é‡
    collection.create_index([("date", ASCENDING), ("symbol", ASCENDING)], unique=True)

    print(f"ğŸš€ Starting download for {len(dates)} days...")

    # æ‰¾å‡ºå·²ç»ä¸‹è½½è¿‡çš„æ—¥æœŸï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
    existing_dates = collection.distinct("date")
    existing_dates_set = set([d.strftime("%Y%m%d") for d in existing_dates])

    download_list = [d for d in dates if d.strftime("%Y%m%d") not in existing_dates_set]
    print(f"   Skipping {len(existing_dates_set)} days, remaining {len(download_list)} days.")

    pbar = tqdm(download_list)
    for dt in pbar:
        date_str = dt.strftime("%Y%m%d")
        pbar.set_description(f"Downloading {date_str}")

        try:
            # è°ƒç”¨æ¥å£
            df = ak.stock_tfp_em(date=date_str)

            if df is None or df.empty:
                # å³ä½¿ä¸ºç©ºä¹Ÿè®°å½•ä¸€æ¡"ç©ºè®°å½•"ï¼Œé˜²æ­¢ä¸‹æ¬¡é‡å¤è¯·æ±‚ï¼ˆå¯é€‰ï¼‰
                continue

            # æ•°æ®æ¸…æ´—
            ops = []
            for _, row in df.iterrows():
                symbol = str(row['ä»£ç '])
                name = str(row['åç§°'])
                reason = str(row['åœç‰ŒåŸå› ']) if 'åœç‰ŒåŸå› ' in row else ""

                # æ—¶é—´å­—æ®µå¤„ç†
                suspend_time = row.get('åœç‰Œæ—¶é—´')  # å¯èƒ½æ˜¯ datetime æˆ– str
                resumption_time = row.get('é¢„è®¡å¤ç‰Œæ—¶é—´')

                doc = {
                    "date": dt,  # è¿™é‡Œçš„ date æ˜¯"æŸ¥è¯¢æ—¥æœŸ"ï¼Œå³å…¬å‘Šå‘å¸ƒæ—¥
                    "symbol": symbol,
                    "name": name,
                    "reason": reason,
                    "suspend_at": str(suspend_time) if pd.notna(suspend_time) else None,
                    "resume_at": str(resumption_time) if pd.notna(resumption_time) else None,
                    "raw_source": "ak.stock_tfp_em"
                }

                ops.append(
                    UpdateOne(
                        {"date": dt, "symbol": symbol},
                        {"$set": doc},
                        upsert=True
                    )
                )

            if ops:
                collection.bulk_write(ops)

        except Exception as e:
            pbar.write(f"âš ï¸ Error on {date_str}: {e}")
            # é‡åˆ°ç½‘ç»œé”™è¯¯ç¨å¾®åœä¸€ä¸‹
            time.sleep(1)

        # ç¤¼è²Œé™æµ
        time.sleep(0.1)

    print("âœ… Step 1: Download Completed.")


def aggregate_to_stock_history(db):
    """
    Step 2: å°†æ¯æ—¥æ•£ç‚¹æ•°æ®èšåˆä¸ºä»¥è‚¡ç¥¨ä¸ºç»´åº¦çš„äº‹ä»¶åˆ—è¡¨
    """
    print("\nğŸ”„ Step 2: Aggregating data to [stock_status_history]...")
    source_col = db[COL_DAILY_RAW]
    target_col = db[COL_TARGET]

    # 1. è·å–æ‰€æœ‰æ¶‰åŠçš„è‚¡ç¥¨
    symbols = source_col.distinct("symbol")
    print(f"   Found {len(symbols)} stocks with suspension records.")

    ops = []
    pbar = tqdm(symbols)

    for symbol in pbar:
        # è·å–è¯¥è‚¡ç¥¨çš„æ‰€æœ‰è®°å½•ï¼ŒæŒ‰æ—¥æœŸæ’åº
        cursor = source_col.find({"symbol": symbol}).sort("date", ASCENDING)
        records = list(cursor)

        if not records:
            continue

        # è½¬æ¢æ ¼å¼
        suspension_list = []
        for r in records:
            # æ¸…æ´—ä¸€ä¸‹æ—¥æœŸ
            try:
                start_dt = pd.to_datetime(r['suspend_at']) if r.get('suspend_at') else r['date']
                end_dt = pd.to_datetime(r['resume_at']) if r.get('resume_at') else None

                item = {
                    "start": start_dt,
                    "reason": r.get('reason', '')
                }
                if end_dt:
                    item['end'] = end_dt

                suspension_list.append(item)
            except:
                continue

        # ç®€å•çš„å»é‡é€»è¾‘ï¼ˆå› ä¸ºæœ‰äº›é•¿åœç‰Œå¯èƒ½æ¯å¤©éƒ½åœ¨æ¦œå•ä¸Šï¼‰
        # è¿™é‡Œæˆ‘ä»¬æš‚ä¸”å…¨éƒ¨å­˜å…¥ï¼ŒDataLoader è¯»å–æ—¶å¯ä»¥ç”¨åŒºé—´åˆå¹¶é€»è¾‘
        # æˆ–è€…åªå­˜ unique çš„ start_date

        if suspension_list:
            ops.append(
                UpdateOne(
                    {"symbol": symbol},
                    {"$set": {
                        "suspensions_em": suspension_list,  # ä½¿ç”¨æ–°å­—æ®µé¿å…è¦†ç›–ä¹‹å‰çš„ inference ç»“æœï¼Œæ–¹ä¾¿å¯¹æ¯”
                        "suspensions_source": "eastmoney_api",
                        "updated_at": datetime.now()
                    }},
                    upsert=True
                )
            )

        if len(ops) >= 500:
            target_col.bulk_write(ops)
            ops = []

    if ops:
        target_col.bulk_write(ops)

    print("âœ… Aggregation Completed.")


if __name__ == "__main__":
    db_client = get_db()

    # 1. è·å–æ—¥å†
    calendar_dates = get_trading_calendar(db_client)

    # 2. ä¸‹è½½æ•°æ® (è€—æ—¶è¾ƒé•¿ï¼Œæ”¯æŒæ–­ç‚¹)
    download_daily_suspensions(db_client, calendar_dates)

    # 3. èšåˆå…¥åº“
    # aggregate_to_stock_history(db_client)