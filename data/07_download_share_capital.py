"""
Script 07 (V2.0): Download Share Capital History (Incremental Update)
---------------------------------------------------------------------
ç›®æ ‡: å¢é‡ä¸‹è½½è‚¡ç¥¨è‚¡æœ¬å˜åŠ¨å†å² (share_capital)ã€‚
ç­–ç•¥:
  1. æŸ¥è¯¢æ•°æ®åº“ä¸­è¯¥è‚¡ç¥¨å·²æœ‰çš„æœ€æ–°å˜åŠ¨æ—¥æœŸ (date)ã€‚
  2. è®¾å®š API çš„ start_date ä¸ºè¯¥æœ€æ–°æ—¥æœŸçš„å‰ä¸€å¤© (å®‰å…¨å›æº¯)ã€‚
  3. ä»…ä¸‹è½½æ–°å¢çš„è®°å½•ã€‚
"""

import akshare as ak
import pandas as pd
import time
from datetime import datetime, timedelta
from tqdm import tqdm
from pymongo import MongoClient, UpdateOne

# ==========================================
# é…ç½®é¡¹ (Configuration)
# ==========================================
MONGO_HOST = "localhost"
MONGO_PORT = 27017
DB_NAME = "vnpy_stock"
COLLECTION_NAME = "share_capital"
# é¦–æ¬¡ä¸‹è½½çš„èµ·å§‹æ—¥æœŸ
INITIAL_START_DATE = "19900101"

def get_db():
    """è·å–æ•°æ®åº“è¿æ¥"""
    client = MongoClient(host=MONGO_HOST, port=MONGO_PORT)
    return client[DB_NAME]

def get_stock_list() -> list:
    """è·å–å¾…ä¸‹è½½çš„è‚¡ç¥¨åˆ—è¡¨ (ä»æœ¬åœ° stock_info è·å–)"""
    db = get_db()
    # ä¼˜å…ˆä» stock_info è·å– A è‚¡/åŒ—äº¤æ‰€ä»£ç 
    cursor = db["stock_info"].find(
        {"category": {"$in": ["STOCK_A", "STOCK_BJ", "UNKNOWN_A"]}},
        {"symbol": 1}
    )
    symbols = [doc["symbol"] for doc in cursor]
    return sorted(list(set(symbols)))

def get_last_recorded_date(symbol: str, db) -> str:
    """
    [NEW] æŸ¥è¯¢æ•°æ®åº“ä¸­è¯¥è‚¡ç¥¨è‚¡æœ¬å˜åŠ¨çš„æœ€æ–°æ—¥æœŸï¼Œå¹¶è¿”å›ä¸‹ä¸€å¤©çš„ YYYYMMDD æ ¼å¼ã€‚
    """
    doc = db[COLLECTION_NAME].find_one(
        {"symbol": symbol},
        sort=[("date", -1)],
        projection={"date": 1}
    )

    if doc and 'date' in doc:
        # DB å­˜å‚¨æ ¼å¼æ˜¯ YYYY-MM-DD
        latest_dt = datetime.strptime(doc['date'], "%Y-%m-%d")
        # å®‰å…¨èµ·è§ï¼Œä»æœ€æ–°è®°å½•çš„**å½“å¤©**å¼€å§‹é‡æ–°ä¸‹è½½ï¼ˆè®© upsert è¦†ç›–é‡å¤è®°å½•ï¼‰
        return latest_dt.strftime("%Y%m%d")

    # å¦‚æœæ²¡æœ‰è®°å½•ï¼Œè¿”å›å…¨å±€èµ·å§‹æ—¥æœŸ
    return INITIAL_START_DATE

def download_and_save(symbol: str, db):
    """
    ä¸‹è½½å•ä¸ªè‚¡ç¥¨çš„è‚¡æœ¬å˜åŠ¨å¹¶å­˜å…¥ MongoDB (å¢é‡æ¨¡å¼)
    """

    # 1. è·å–å¢é‡èµ·å§‹æ—¥æœŸ
    start_date_str = get_last_recorded_date(symbol, db)

    # å¦‚æœæœ€æ–°æ—¥æœŸæ˜¯ä»Šå¤©ï¼Œåˆ™æ— éœ€æ›´æ–°
    today_str = datetime.now().strftime("%Y%m%d")
    if start_date_str == today_str:
        return 0

    try:
        # 2. æ¥å£è°ƒç”¨ (ä½¿ç”¨å¢é‡èµ·å§‹æ—¥æœŸ)
        current_date = today_str
        df = ak.stock_share_change_cninfo(
            symbol=symbol,
            start_date=start_date_str, # âœ… ä½¿ç”¨å¢é‡æ—¥æœŸ
            end_date=current_date
        )

        if df is None or df.empty:
            return 0

        # 3. å­—æ®µæ˜ å°„å’Œæ¸…æ´—
        rename_map = {
            'å˜åŠ¨æ—¥æœŸ': 'date',
            'æ€»è‚¡æœ¬': 'total_shares',
            'å·²æµé€šè‚¡ä»½': 'float_shares',
            'å˜åŠ¨åŸå› ': 'change_reason'
        }

        if not set(rename_map.keys()).issubset(df.columns):
            return 0

        df = df.rename(columns=rename_map)

        df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')

        def clean_shares(val):
            if pd.isna(val) or val == '':
                return 0.0
            try:
                return float(val) * 10000 # ä¸‡è‚¡ -> è‚¡
            except:
                return 0.0

        df['total_shares'] = df['total_shares'].apply(clean_shares)
        df['float_shares'] = df['float_shares'].apply(clean_shares)

        # 4. æ„é€ å†™å…¥æ“ä½œ (Upsert)
        requests = []
        for _, row in df.iterrows():
            filter_doc = {
                "symbol": symbol,
                "date": row["date"]
            }
            update_doc = {
                "$set": {
                    "total_shares": row["total_shares"],
                    "float_shares": row["float_shares"],
                    "change_reason": row["change_reason"],
                    "updated_at": datetime.now()
                }
            }
            requests.append(UpdateOne(filter_doc, update_doc, upsert=True))

        if requests:
            db[COLLECTION_NAME].bulk_write(requests)
            return len(requests)

        return 0

    except Exception as e:
        # print(f"Error {symbol}: {e}")
        return 0

def run():
    print("ğŸš€ å¯åŠ¨ [Aè‚¡è‚¡æœ¬å˜åŠ¨ä¸‹è½½å™¨] (å¢é‡ V2.0)...")

    db = get_db()
    symbols = get_stock_list()
    print(f"ğŸ“Š ç›®æ ‡è‚¡ç¥¨æ•°é‡: {len(symbols)}")

    if not symbols:
        return

    # ç®€å•è¿›åº¦æ¡
    pbar = tqdm(symbols)
    for symbol in pbar:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡ï¼ˆå¦‚æœæ˜¯æœ€æ–°æ—¥æœŸåˆ™ä¸æ˜¾ç¤ºï¼‰
        start_date_check = get_last_recorded_date(symbol, db)
        today_str = datetime.now().strftime("%Y%m%d")

        if start_date_check == today_str:
            pbar.set_description(f"è·³è¿‡ {symbol} (å·²æœ€æ–°)")
            continue

        pbar.set_description(f"ä¸‹è½½ {symbol} (Start: {start_date_check})")
        download_and_save(symbol, db)
        time.sleep(0.1)

    print("\nâœ… å¢é‡ä¸‹è½½å®Œæˆã€‚")

if __name__ == "__main__":
    run()