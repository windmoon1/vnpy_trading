"""
è„šæœ¬ 07 (V2.0): è‚¡æœ¬æ•°æ®å…¨èƒ½ä¸‹è½½å™¨ (Download & Fuse)
-------------------------------------------------------
åŠŸèƒ½:
1. [Download] ä» AKShare ä¸‹è½½æœ€æ–°çš„è‚¡æœ¬å˜åŠ¨è®°å½• (æ¥æº: å·¨æ½®èµ„è®¯).
2. [Fuse] è‡ªåŠ¨å» bar_daily (æ—¥çº¿è¡¨) æŸ¥æ‰¾å¯¹åº”çš„ Aè‚¡æµé€šè‚¡æœ¬ (outstanding_share).
3. [Clean] å°†æŸ¥åˆ°çš„å‡†ç¡®æµé€šè‚¡æœ¬å›å†™åˆ° share_capital è¡¨çš„ float_shares_a å­—æ®µ.

å‰ç½®æ¡ä»¶: å»ºè®®å…ˆè¿è¡Œ è„šæœ¬ 02 (ä¸‹è½½æ—¥çº¿)ï¼Œä»¥ä¿è¯æœ‰æœ€æ–°çš„è¡Œæƒ…æ•°æ®å¯ä¾›ç¼åˆã€‚
"""
import time
import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
from tqdm import tqdm
from pymongo import MongoClient, UpdateOne, ASCENDING, DESCENDING

# --- é…ç½® ---
MONGO_HOST = "localhost"
MONGO_PORT = 27017
DB_NAME = "vnpy_stock"

# è¿æ¥æ•°æ®åº“
CLIENT = MongoClient(MONGO_HOST, MONGO_PORT)
DB = CLIENT[DB_NAME]
COL_CAPITAL = DB["share_capital"]
COL_BARS = DB["bar_daily"]
COL_INFO = DB["stock_info"]

def normalize_date(date_obj):
    """é€šç”¨æ—¥æœŸæ¸…æ´—å·¥å…·"""
    if isinstance(date_obj, str):
        try:
            if "T" in date_obj:
                return datetime.strptime(date_obj.split("T")[0], "%Y-%m-%d")
            return datetime.strptime(date_obj, "%Y-%m-%d")
        except:
            return None
    elif isinstance(date_obj, datetime):
        return date_obj.replace(hour=0, minute=0, second=0, microsecond=0)
    elif hasattr(date_obj, "date"):
        return date_obj.to_pydatetime().replace(hour=0, minute=0, second=0, microsecond=0)
    return None

def get_stock_list():
    """è·å–ä»»åŠ¡åˆ—è¡¨"""
    cursor = COL_INFO.find({"category": {"$in": ["STOCK_A", "STOCK_BJ"]}}, {"symbol": 1, "name": 1})
    return list(cursor)

def download_capital_cninfo(symbol):
    """Step 1: ä¸‹è½½ CNINFO åŸå§‹è‚¡æœ¬å˜åŠ¨æ•°æ®"""
    try:
        # æ³¨æ„ï¼šAKShare æ­¤æ¥å£è¿”å›è¯¥è‚¡ç¥¨å†å²æ‰€æœ‰å˜åŠ¨ï¼Œæˆ‘ä»¬éœ€è¦åšå¢é‡è¿‡æ»¤
        df = ak.stock_share_changes_cninfo(symbol=symbol)
        if df.empty: return 0

        updates = []
        for _, row in df.iterrows():
            date_str = str(row['date'])
            date_obj = normalize_date(date_str)
            if not date_obj: continue

            # åŸå§‹æ•°æ® (æ³¨æ„ï¼šè¿™é‡Œçš„ float_shares åŒ…å«äº† H è‚¡ï¼Œæ˜¯â€œå…¨çƒæµé€šè‚¡æœ¬â€)
            total_shares = float(row['æ€»è‚¡æœ¬'])
            float_shares_global = float(row['æµé€šAè‚¡']) if 'æµé€šAè‚¡' in row else float(row.get('æµé€šè‚¡æœ¬', 0))
            reason = row.get('å˜åŠ¨åŸå› ', '')

            # æ„é€ åŸºç¡€æ–‡æ¡£
            doc = {
                "symbol": symbol,
                "date": date_obj,
                "total_shares": total_shares,
                "float_shares": float_shares_global, # å­˜ä¸‹æ¥ä½œä¸ºå‚è€ƒï¼Œä½†ä¸ç”¨äºæ ¸å¿ƒè®¡ç®—
                "change_reason": reason,
                "update_at": datetime.now()
            }

            # Upsert: æŒ‰ç…§ symbol + date å”¯ä¸€ç´¢å¼•æ›´æ–°
            filter_doc = {"symbol": symbol, "date": date_obj}
            updates.append(UpdateOne(filter_doc, {"$set": doc}, upsert=True))

        if updates:
            res = COL_CAPITAL.bulk_write(updates, ordered=False)
            return res.upserted_count + res.modified_count
        return 0

    except Exception as e:
        # æŸäº›è‚¡ç¥¨å¯èƒ½æ²¡æœ‰æ•°æ®ï¼Œå¿½ç•¥æŠ¥é”™
        return 0

def fuse_float_shares(symbol):
    """Step 2: ç¼åˆé€»è¾‘ - ä» bar_daily è¡¥å…¨ float_shares_a"""
    # åªæŸ¥æ‰¾è¯¥è‚¡ç¥¨ç¼ºå¤± float_shares_a çš„è®°å½•
    pending_cursor = COL_CAPITAL.find({
        "symbol": symbol,
        "float_shares_a": {"$exists": False}
    })

    updates = []

    for cap_doc in pending_cursor:
        raw_date = cap_doc.get("date")
        target_date = normalize_date(raw_date)
        if not target_date: continue

        # æŸ¥æ‰¾ bar_daily (é€»è¾‘åŒ Script 18)
        # æ‰¾ >= å˜åŠ¨æ—¥ çš„æœ€è¿‘ä¸€æ¡æœ‰ outstanding_share çš„ K çº¿
        bar_doc = COL_BARS.find_one(
            {
                "symbol": symbol,
                "datetime": {"$gte": target_date},
                "outstanding_share": {"$exists": True}
            },
            sort=[("datetime", ASCENDING)]
        )

        if bar_doc:
            bar_date = normalize_date(bar_doc["datetime"])
            days_diff = (bar_date - target_date).days

            # å…è®¸ 10 å¤©å†…çš„åå·®ï¼ˆåº”å¯¹åœç‰Œæˆ–éäº¤æ˜“æ—¥ï¼‰
            if 0 <= days_diff <= 10:
                real_float_a = bar_doc["outstanding_share"]
                updates.append(
                    UpdateOne(
                        {"_id": cap_doc["_id"]},
                        {"$set": {"float_shares_a": real_float_a}}
                    )
                )

    if updates:
        res = COL_CAPITAL.bulk_write(updates, ordered=False)
        return res.modified_count
    return 0

def run():
    print("ğŸš€ å¯åŠ¨ [è‚¡æœ¬æ•°æ®å…¨èƒ½ä¸‹è½½å™¨ V2.0] (Download + Fuse)...")

    tasks = get_stock_list()
    print(f"ğŸ“Š å¾…å¤„ç†è‚¡ç¥¨: {len(tasks)} åª")

    pbar = tqdm(tasks, unit="stock")

    total_downloaded = 0
    total_fused = 0

    for task in pbar:
        symbol = task['symbol']
        name = task['name']

        pbar.set_description(f"Processing {name}")

        # 1. ä¸‹è½½åŸºç¡€æ•°æ®
        d_count = download_capital_cninfo(symbol)

        # 2. æ‰§è¡Œç¼åˆ (æ— è®ºæ˜¯å¦ä¸‹è½½äº†æ–°æ•°æ®ï¼Œéƒ½æ£€æŸ¥ä¸€éæœ‰æ²¡æœ‰æ¼è¡¥çš„)
        f_count = fuse_float_shares(symbol)

        total_downloaded += d_count
        total_fused += f_count

        # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        time.sleep(0.05)

    print(f"\nâœ¨ ä»»åŠ¡å®Œæˆ Report:")
    print(f"   - æ–°å¢/æ›´æ–°å˜åŠ¨è®°å½•: {total_downloaded}")
    print(f"   - æˆåŠŸç¼åˆAè‚¡æµé€šå€¼: {total_fused}")
    print("âœ… æ•°æ®åº“çŠ¶æ€: share_capital è¡¨å·²åŒ…å« float_shares_a å­—æ®µã€‚")

if __name__ == "__main__":
    run()